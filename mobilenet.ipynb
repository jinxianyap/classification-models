{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mobilenet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP72k4TMAyJAZPCS96CVewP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jinxianyap/classification-models/blob/master/mobilenet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4fcjIXc07Kp",
        "outputId": "bd85dd56-4763-4b0f-f292-5edad65b1676",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        }
      },
      "source": [
        "!pip install --upgrade gspread\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive/My\\ Drive/WISE AI/Classification"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: gspread in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from gspread) (1.17.2)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from gspread) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: requests>=2.2.1 in /usr/local/lib/python3.6/dist-packages (from gspread) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.12.0->gspread) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.12.0->gspread) (4.6)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.12.0->gspread) (50.3.0)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.12.0->gspread) (4.1.1)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.12.0->gspread) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib>=0.4.1->gspread) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.2.1->gspread) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.2.1->gspread) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.2.1->gspread) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.2.1->gspread) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth>=1.12.0->gspread) (0.4.8)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.1.0)\n",
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "/gdrive/My Drive/WISE AI/Classification\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Xqotb3X1Qtt"
      },
      "source": [
        "import os\n",
        "import csv   \n",
        "import numpy as np\n",
        "import json\n",
        "from numpy import asarray\n",
        "from numpy import save\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from sklearn.model_selection import train_test_split\n",
        "from matplotlib import pyplot\n",
        "from matplotlib.image import imread\n",
        "\n",
        "from keras.applications.mobilenet_v2 import MobileNetV2\n",
        "from keras.applications.mobilenet_v2 import preprocess_input\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import Sequential\n",
        "from keras.layers import Flatten,Dense,BatchNormalization,Activation,Dropout,Conv2D,MaxPooling2D\n",
        "from keras.optimizers import SGD,Adam,RMSprop\n",
        "from keras.regularizers import l1, l2\n",
        "from keras.constraints import max_norm\n",
        "from sklearn.model_selection import KFold\n",
        "from keras.models import model_from_json\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "import gspread\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default())\n",
        "target_height = 224\n",
        "target_width = 224\n",
        "classes_dir = './classes/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gw-9hIUw1SeC"
      },
      "source": [
        "def load_dataset():\n",
        "  classes = os.listdir(classes_dir)\n",
        "  train_photos, test_photos, train_labels, test_labels, train_paths, test_paths = list(), list(), list(), list(), list(), list()\n",
        "\n",
        "  def get_encoding(class_name):\n",
        "    return list(map(lambda c: 1 if c == class_name else 0, classes))\n",
        "\n",
        "  for each in classes:\n",
        "    i = 0;\n",
        "    for image in os.listdir(classes_dir + each):\n",
        "      output = get_encoding(each)\n",
        "      photo = load_img(classes_dir + each + \"/\" + image, target_size=(target_height, target_width))\n",
        "      photo = img_to_array(photo)\n",
        "\n",
        "      if i > 2:\n",
        "        train_photos.append(photo)\n",
        "        train_labels.append(output)\n",
        "        train_paths.append(each + \"/\" + image)\n",
        "      else:\n",
        "        test_photos.append(photo)\n",
        "        test_labels.append(output)\n",
        "        test_paths.append(each + \"/\" + image)\n",
        "      i += 1;\n",
        "\n",
        "  X_train = asarray(train_photos)\n",
        "  y_train = asarray(train_labels)\n",
        "  X_test = asarray(test_photos)\n",
        "  y_test = asarray(test_labels)\n",
        "  train_paths = asarray(train_paths)\n",
        "  test_paths = asarray(test_paths)\n",
        "\n",
        "  return classes, X_train, y_train, X_test, y_test, train_paths, test_paths"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfeM8P471UPH"
      },
      "source": [
        "def build_model():\n",
        "  base_model = MobileNetV2(\n",
        "      include_top=False,\n",
        "      alpha = 0.35,\n",
        "      weights=\"imagenet\",\n",
        "      pooling=\"max\",\n",
        "      input_shape=(224, 224, 3)\n",
        "  )\n",
        "  model = Sequential()\n",
        "  model.add(base_model)\n",
        "  model.add(Flatten())\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(256, activation='relu'))\n",
        "  model.add(Dense(6, activation='softmax', kernel_regularizer=l1(0.01)))\n",
        "  model.summary()\n",
        "  opt = SGD(lr=0.0001, momentum=0.9)\n",
        "  model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgZzDRgM1VnS"
      },
      "source": [
        "def train_model(model, dataX, dataY, testX, testY):\n",
        "  # datagen = ImageDataGenerator(rescale=1./255)\n",
        "  # testgen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "  history = model.fit(dataX, dataY, epochs=200, validation_data=(testX, testY), verbose=1)\n",
        "  _, acc = model.evaluate(testX, testY, verbose=0)\n",
        "  print('> %.3f' % (acc * 100.0))\n",
        "\n",
        "  return model, history, acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5csTaBE1Y49"
      },
      "source": [
        "def plot_metrics(history):\n",
        "  fig, (ax1, ax2) = pyplot.subplots(2)\n",
        "  plot_loss(history, ax1)\n",
        "  plot_accuracy(history, ax2)\n",
        "\n",
        "def plot_loss(each, ax):\n",
        "  ax.set_title('Cross Entropy Loss')\n",
        "  ax.plot(each.history['loss'], color='blue', label='train')\n",
        "  ax.plot(each.history['val_loss'], color='orange', label='test')\n",
        "\n",
        "def plot_accuracy(each, ax):\n",
        "  ax.set_title('Classification Accuracy')\n",
        "  ax.plot(each.history['accuracy'], color='blue', label='train')\n",
        "  ax.plot(each.history['val_accuracy'], color='orange', label='test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OG4HPTIX1agc"
      },
      "source": [
        "def decode(vals):\n",
        "  return list(map(lambda x: list_to_num(x), vals))\n",
        "\n",
        "def prettify_floats(vals):\n",
        "  return list(map(lambda x: list(map(lambda y: \"%.2f\" % y, x)), vals))\n",
        "\n",
        "def list_to_num(ls):\n",
        "  max = -1\n",
        "  pos = 0\n",
        "  for i in range(len(ls)):\n",
        "    if ls[i] > max:\n",
        "      max = ls[i]\n",
        "      pos = i\n",
        "  return pos\n",
        "\n",
        "def get_table_metrics(model, classes, testX, testY):\n",
        "  print(classification_report(decode(testY), decode(model.predict(testX)), target_names=classes))\n",
        "  return json.dumps(classification_report(decode(testY), decode(model.predict(testX)), target_names=classes, output_dict=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3A_cyFhszRg"
      },
      "source": [
        "def save_model(model, name):\n",
        "  fd_model = os.open('./models/%s_classification.json' % name, os.O_RDWR|os.O_CREAT) \n",
        "  model_json = model.to_json()\n",
        "  os.write(fd_model, bytes(model_json, 'utf-8'))\n",
        "  os.close(fd_model)\n",
        "\n",
        "  model.save_weights(\"./weights/%s_classification.h5\" % name)\n",
        "  print(\"Saved model to disk\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcPLO1WP1eaO"
      },
      "source": [
        "def write_to_output(model, name, classes, dataX, dataY, paths, is_test):\n",
        "  def next_available_row(worksheet):\n",
        "    str_list = list(filter(None, worksheet.col_values(1)))\n",
        "    return len(str_list)+1\n",
        "\n",
        "  worksheet = gc.open('results').worksheet(name)\n",
        "  row = next_available_row(worksheet)\n",
        "\n",
        "  for i in range(len(dataX)):\n",
        "    first_row = str(row)\n",
        "    worksheet.update_acell(\"A{}\".format(first_row), name)\n",
        "    worksheet.update_acell(\"B{}\".format(first_row), 'softmax')\n",
        "    worksheet.update_acell(\"C{}\".format(first_row), True)\n",
        "    worksheet.update_acell(\"D{}\".format(first_row), 'test' if is_test else 'train')\n",
        "    worksheet.update_acell(\"E{}\".format(first_row), 'classes')\n",
        "    worksheet.update_acell(\"F{}\".format(first_row), str(paths[i]))\n",
        "    worksheet.update_acell(\"G{}\".format(first_row), classes[list_to_num(dataY[i])])\n",
        "    worksheet.update_acell(\"H{}\".format(first_row), classes[decode(model.predict(dataX[i:i+1]))[0]])\n",
        "\n",
        "    row += 1\n",
        "\n",
        "  print('Written to output CSV')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qU-VDsOp1f1C",
        "outputId": "9c4d626a-c06a-47a4-e8ba-a0c4586e9d5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "classes, trainX, trainY, testX, testY, train_paths, test_paths = load_dataset()\n",
        "\n",
        "trainX, testX = preprocess_input(trainX), preprocess_input(testX)\n",
        "\n",
        "model = build_model()\n",
        "\n",
        "model, hists, accs = train_model(model, trainX, trainY, testX, testY)\n",
        "\n",
        "plot_metrics(hists)\n",
        "\n",
        "report = get_table_metrics(model, classes, testX, testY)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "mobilenetv2_0.35_224 (Functi (None, 1280)              410208    \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 256)               327936    \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 6)                 1542      \n",
            "=================================================================\n",
            "Total params: 739,686\n",
            "Trainable params: 725,606\n",
            "Non-trainable params: 14,080\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "2/2 [==============================] - ETA: 0s - loss: 11.1539 - accuracy: 0.1346WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0259s vs `on_train_batch_end` time: 0.0445s). Check your callbacks.\n",
            "2/2 [==============================] - 1s 409ms/step - loss: 11.1539 - accuracy: 0.1346 - val_loss: 7.3720 - val_accuracy: 0.1667\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 9.1767 - accuracy: 0.1923 - val_loss: 5.8480 - val_accuracy: 0.1111\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 7.0812 - accuracy: 0.2115 - val_loss: 5.0416 - val_accuracy: 0.1667\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 6.8095 - accuracy: 0.3269 - val_loss: 4.4652 - val_accuracy: 0.2222\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 4.3415 - accuracy: 0.4423 - val_loss: 4.5403 - val_accuracy: 0.2778\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 3.5107 - accuracy: 0.5000 - val_loss: 4.9595 - val_accuracy: 0.2222\n",
            "Epoch 7/200\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 4.0572 - accuracy: 0.5385 - val_loss: 5.1543 - val_accuracy: 0.2222\n",
            "Epoch 8/200\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 3.4065 - accuracy: 0.5192 - val_loss: 5.1033 - val_accuracy: 0.2778\n",
            "Epoch 9/200\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 2.9033 - accuracy: 0.6154 - val_loss: 4.9651 - val_accuracy: 0.2778\n",
            "Epoch 10/200\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 1.8580 - accuracy: 0.8654 - val_loss: 4.9340 - val_accuracy: 0.2778\n",
            "Epoch 11/200\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 3.3954 - accuracy: 0.6538 - val_loss: 4.7451 - val_accuracy: 0.2778\n",
            "Epoch 12/200\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 2.0278 - accuracy: 0.7692 - val_loss: 4.4892 - val_accuracy: 0.2778\n",
            "Epoch 13/200\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 1.6438 - accuracy: 0.8462 - val_loss: 4.2437 - val_accuracy: 0.2778\n",
            "Epoch 14/200\n",
            "2/2 [==============================] - 0s 84ms/step - loss: 2.0351 - accuracy: 0.8269 - val_loss: 4.0884 - val_accuracy: 0.3333\n",
            "Epoch 15/200\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 1.4469 - accuracy: 0.8846 - val_loss: 4.0703 - val_accuracy: 0.2778\n",
            "Epoch 16/200\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 1.5695 - accuracy: 0.8846 - val_loss: 4.0778 - val_accuracy: 0.2778\n",
            "Epoch 17/200\n",
            "2/2 [==============================] - 0s 92ms/step - loss: 1.8383 - accuracy: 0.8462 - val_loss: 4.0261 - val_accuracy: 0.3333\n",
            "Epoch 18/200\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 1.3620 - accuracy: 0.9423 - val_loss: 3.9963 - val_accuracy: 0.3889\n",
            "Epoch 19/200\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 1.9587 - accuracy: 0.8269 - val_loss: 3.9808 - val_accuracy: 0.3333\n",
            "Epoch 20/200\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 1.4013 - accuracy: 0.9038 - val_loss: 3.9963 - val_accuracy: 0.2778\n",
            "Epoch 21/200\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 1.7105 - accuracy: 0.8462 - val_loss: 3.9238 - val_accuracy: 0.2778\n",
            "Epoch 22/200\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 1.3108 - accuracy: 0.9423 - val_loss: 3.7631 - val_accuracy: 0.2778\n",
            "Epoch 23/200\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 1.4025 - accuracy: 0.9423 - val_loss: 3.6074 - val_accuracy: 0.2778\n",
            "Epoch 24/200\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 1.3249 - accuracy: 0.9808 - val_loss: 3.4718 - val_accuracy: 0.2778\n",
            "Epoch 25/200\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 1.4070 - accuracy: 0.9423 - val_loss: 3.3422 - val_accuracy: 0.3333\n",
            "Epoch 26/200\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 1.4008 - accuracy: 0.8846 - val_loss: 3.2359 - val_accuracy: 0.3889\n",
            "Epoch 27/200\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 1.4236 - accuracy: 0.9231 - val_loss: 3.1804 - val_accuracy: 0.4444\n",
            "Epoch 28/200\n",
            "2/2 [==============================] - 0s 91ms/step - loss: 1.3453 - accuracy: 0.9231 - val_loss: 3.0995 - val_accuracy: 0.4444\n",
            "Epoch 29/200\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 1.4145 - accuracy: 0.9231 - val_loss: 3.0694 - val_accuracy: 0.4444\n",
            "Epoch 30/200\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 1.5265 - accuracy: 0.8846 - val_loss: 3.0621 - val_accuracy: 0.4444\n",
            "Epoch 31/200\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 1.1973 - accuracy: 1.0000 - val_loss: 3.0981 - val_accuracy: 0.4444\n",
            "Epoch 32/200\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 1.6201 - accuracy: 0.9038 - val_loss: 3.1739 - val_accuracy: 0.3889\n",
            "Epoch 33/200\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 1.2740 - accuracy: 0.9423 - val_loss: 3.3411 - val_accuracy: 0.3889\n",
            "Epoch 34/200\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 1.2052 - accuracy: 0.9808 - val_loss: 3.5077 - val_accuracy: 0.3333\n",
            "Epoch 35/200\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 1.2260 - accuracy: 0.9615 - val_loss: 3.6044 - val_accuracy: 0.3333\n",
            "Epoch 36/200\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 1.2815 - accuracy: 0.9615 - val_loss: 3.5956 - val_accuracy: 0.3333\n",
            "Epoch 37/200\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 1.2028 - accuracy: 0.9808 - val_loss: 3.6148 - val_accuracy: 0.3333\n",
            "Epoch 38/200\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 1.1923 - accuracy: 0.9808 - val_loss: 3.6861 - val_accuracy: 0.3333\n",
            "Epoch 39/200\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 1.1661 - accuracy: 1.0000 - val_loss: 3.7421 - val_accuracy: 0.3333\n",
            "Epoch 40/200\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 1.3544 - accuracy: 0.9231 - val_loss: 3.7487 - val_accuracy: 0.2778\n",
            "Epoch 41/200\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 1.3925 - accuracy: 0.9423 - val_loss: 3.7567 - val_accuracy: 0.2778\n",
            "Epoch 42/200\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 1.1775 - accuracy: 1.0000 - val_loss: 3.7411 - val_accuracy: 0.3333\n",
            "Epoch 43/200\n",
            "2/2 [==============================] - 0s 93ms/step - loss: 1.2953 - accuracy: 0.9423 - val_loss: 3.7238 - val_accuracy: 0.3333\n",
            "Epoch 44/200\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 1.1671 - accuracy: 1.0000 - val_loss: 3.6998 - val_accuracy: 0.3889\n",
            "Epoch 45/200\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 1.1677 - accuracy: 1.0000 - val_loss: 3.6610 - val_accuracy: 0.3889\n",
            "Epoch 46/200\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 1.2127 - accuracy: 0.9615 - val_loss: 3.6002 - val_accuracy: 0.3889\n",
            "Epoch 47/200\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 1.2391 - accuracy: 0.9808 - val_loss: 3.5434 - val_accuracy: 0.3333\n",
            "Epoch 48/200\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 1.1939 - accuracy: 0.9808 - val_loss: 3.4557 - val_accuracy: 0.3333\n",
            "Epoch 49/200\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 1.2820 - accuracy: 0.9808 - val_loss: 3.3640 - val_accuracy: 0.3889\n",
            "Epoch 50/200\n",
            "2/2 [==============================] - 0s 84ms/step - loss: 1.2704 - accuracy: 0.9615 - val_loss: 3.2504 - val_accuracy: 0.3889\n",
            "Epoch 51/200\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 1.1807 - accuracy: 0.9808 - val_loss: 3.1424 - val_accuracy: 0.3889\n",
            "Epoch 52/200\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 1.2405 - accuracy: 0.9423 - val_loss: 3.0692 - val_accuracy: 0.3889\n",
            "Epoch 53/200\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 1.1617 - accuracy: 1.0000 - val_loss: 3.0104 - val_accuracy: 0.4444\n",
            "Epoch 54/200\n",
            "2/2 [==============================] - 0s 84ms/step - loss: 1.1919 - accuracy: 0.9808 - val_loss: 2.9711 - val_accuracy: 0.4444\n",
            "Epoch 55/200\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 1.2129 - accuracy: 0.9615 - val_loss: 2.9641 - val_accuracy: 0.4444\n",
            "Epoch 56/200\n",
            "2/2 [==============================] - 0s 84ms/step - loss: 1.1999 - accuracy: 0.9808 - val_loss: 3.0057 - val_accuracy: 0.4444\n",
            "Epoch 57/200\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 1.3421 - accuracy: 0.9423 - val_loss: 3.0921 - val_accuracy: 0.4444\n",
            "Epoch 58/200\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 1.1634 - accuracy: 1.0000 - val_loss: 3.1743 - val_accuracy: 0.4444\n",
            "Epoch 59/200\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 1.2639 - accuracy: 0.9808 - val_loss: 3.1947 - val_accuracy: 0.4444\n",
            "Epoch 60/200\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 1.1600 - accuracy: 1.0000 - val_loss: 3.1756 - val_accuracy: 0.4444\n",
            "Epoch 61/200\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 1.2073 - accuracy: 0.9808 - val_loss: 3.1898 - val_accuracy: 0.4444\n",
            "Epoch 62/200\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 1.2485 - accuracy: 0.9615 - val_loss: 3.1963 - val_accuracy: 0.4444\n",
            "Epoch 63/200\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 1.1534 - accuracy: 1.0000 - val_loss: 3.1749 - val_accuracy: 0.4444\n",
            "Epoch 64/200\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 1.2240 - accuracy: 0.9615 - val_loss: 3.1607 - val_accuracy: 0.3889\n",
            "Epoch 65/200\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 1.1733 - accuracy: 0.9808 - val_loss: 3.1543 - val_accuracy: 0.3889\n",
            "Epoch 66/200\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 1.1515 - accuracy: 1.0000 - val_loss: 3.1400 - val_accuracy: 0.3333\n",
            "Epoch 67/200\n",
            "2/2 [==============================] - 0s 84ms/step - loss: 1.1667 - accuracy: 1.0000 - val_loss: 3.1278 - val_accuracy: 0.2778\n",
            "Epoch 68/200\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 1.1748 - accuracy: 1.0000 - val_loss: 3.1095 - val_accuracy: 0.2778\n",
            "Epoch 69/200\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 1.2457 - accuracy: 0.9808 - val_loss: 3.0905 - val_accuracy: 0.2778\n",
            "Epoch 70/200\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 1.2639 - accuracy: 0.9615 - val_loss: 3.0285 - val_accuracy: 0.3333\n",
            "Epoch 71/200\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 1.2493 - accuracy: 0.9808 - val_loss: 3.0051 - val_accuracy: 0.3333\n",
            "Epoch 72/200\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 1.2649 - accuracy: 0.9615 - val_loss: 2.9989 - val_accuracy: 0.3333\n",
            "Epoch 73/200\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 1.1487 - accuracy: 1.0000 - val_loss: 3.0196 - val_accuracy: 0.3333\n",
            "Epoch 74/200\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 1.1787 - accuracy: 0.9808 - val_loss: 3.0151 - val_accuracy: 0.3333\n",
            "Epoch 75/200\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 1.1472 - accuracy: 1.0000 - val_loss: 3.0047 - val_accuracy: 0.3333\n",
            "Epoch 76/200\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 1.2665 - accuracy: 0.9808 - val_loss: 2.9943 - val_accuracy: 0.3333\n",
            "Epoch 77/200\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 1.1638 - accuracy: 1.0000 - val_loss: 2.9755 - val_accuracy: 0.3333\n",
            "Epoch 78/200\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 1.1699 - accuracy: 0.9808 - val_loss: 2.9361 - val_accuracy: 0.3333\n",
            "Epoch 79/200\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 1.1626 - accuracy: 0.9808 - val_loss: 2.9071 - val_accuracy: 0.3889\n",
            "Epoch 80/200\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 1.1866 - accuracy: 0.9808 - val_loss: 2.8804 - val_accuracy: 0.4444\n",
            "Epoch 81/200\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 1.1594 - accuracy: 1.0000 - val_loss: 2.8705 - val_accuracy: 0.4444\n",
            "Epoch 82/200\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 1.3542 - accuracy: 0.9615 - val_loss: 2.8840 - val_accuracy: 0.3889\n",
            "Epoch 83/200\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 1.1489 - accuracy: 1.0000 - val_loss: 2.9147 - val_accuracy: 0.3889\n",
            "Epoch 84/200\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 1.2099 - accuracy: 0.9808 - val_loss: 2.9410 - val_accuracy: 0.3333\n",
            "Epoch 85/200\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 1.2976 - accuracy: 0.9808 - val_loss: 2.9818 - val_accuracy: 0.3889\n",
            "Epoch 86/200\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 1.1460 - accuracy: 1.0000 - val_loss: 3.0186 - val_accuracy: 0.3333\n",
            "Epoch 87/200\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 1.1566 - accuracy: 1.0000 - val_loss: 3.0482 - val_accuracy: 0.3333\n",
            "Epoch 88/200\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 1.1509 - accuracy: 1.0000 - val_loss: 3.0614 - val_accuracy: 0.3333\n",
            "Epoch 89/200\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 1.1576 - accuracy: 1.0000 - val_loss: 3.0622 - val_accuracy: 0.3333\n",
            "Epoch 90/200\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 1.1473 - accuracy: 1.0000 - val_loss: 3.0572 - val_accuracy: 0.3889\n",
            "Epoch 91/200\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 1.1542 - accuracy: 1.0000 - val_loss: 3.0376 - val_accuracy: 0.3889\n",
            "Epoch 92/200\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 1.1524 - accuracy: 1.0000 - val_loss: 3.0099 - val_accuracy: 0.3889\n",
            "Epoch 93/200\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 1.2136 - accuracy: 0.9808 - val_loss: 3.0169 - val_accuracy: 0.3889\n",
            "Epoch 94/200\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 1.1495 - accuracy: 1.0000 - val_loss: 3.0314 - val_accuracy: 0.3889\n",
            "Epoch 95/200\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 1.1466 - accuracy: 1.0000 - val_loss: 3.0382 - val_accuracy: 0.3889\n",
            "Epoch 96/200\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 1.1406 - accuracy: 1.0000 - val_loss: 3.0448 - val_accuracy: 0.3889\n",
            "Epoch 97/200\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 1.1420 - accuracy: 1.0000 - val_loss: 3.0519 - val_accuracy: 0.3889\n",
            "Epoch 98/200\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 1.1447 - accuracy: 1.0000 - val_loss: 3.0558 - val_accuracy: 0.3889\n",
            "Epoch 99/200\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 1.2304 - accuracy: 0.9615 - val_loss: 3.0344 - val_accuracy: 0.3889\n",
            "Epoch 100/200\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 1.1574 - accuracy: 1.0000 - val_loss: 3.0090 - val_accuracy: 0.4444\n",
            "Epoch 101/200\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 1.1516 - accuracy: 1.0000 - val_loss: 2.9981 - val_accuracy: 0.4444\n",
            "Epoch 102/200\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 1.1718 - accuracy: 0.9808 - val_loss: 2.9941 - val_accuracy: 0.4444\n",
            "Epoch 103/200\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 1.1949 - accuracy: 0.9615 - val_loss: 3.0000 - val_accuracy: 0.4444\n",
            "Epoch 104/200\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 1.1568 - accuracy: 1.0000 - val_loss: 2.9924 - val_accuracy: 0.4444\n",
            "Epoch 105/200\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 1.1436 - accuracy: 1.0000 - val_loss: 2.9806 - val_accuracy: 0.4444\n",
            "Epoch 106/200\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 1.1473 - accuracy: 1.0000 - val_loss: 2.9739 - val_accuracy: 0.4444\n",
            "Epoch 107/200\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 1.2229 - accuracy: 0.9423 - val_loss: 2.9825 - val_accuracy: 0.4444\n",
            "Epoch 108/200\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 1.1439 - accuracy: 1.0000 - val_loss: 3.0094 - val_accuracy: 0.4444\n",
            "Epoch 109/200\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 1.1364 - accuracy: 1.0000 - val_loss: 3.0297 - val_accuracy: 0.4444\n",
            "Epoch 110/200\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 1.1381 - accuracy: 1.0000 - val_loss: 3.0444 - val_accuracy: 0.4444\n",
            "Epoch 111/200\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 1.1701 - accuracy: 0.9808 - val_loss: 3.0345 - val_accuracy: 0.4444\n",
            "Epoch 112/200\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 1.1691 - accuracy: 0.9808 - val_loss: 3.0049 - val_accuracy: 0.5000\n",
            "Epoch 113/200\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 1.1788 - accuracy: 0.9808 - val_loss: 3.0181 - val_accuracy: 0.5000\n",
            "Epoch 114/200\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 1.1372 - accuracy: 1.0000 - val_loss: 3.0272 - val_accuracy: 0.5000\n",
            "Epoch 115/200\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 1.1388 - accuracy: 1.0000 - val_loss: 3.0353 - val_accuracy: 0.4444\n",
            "Epoch 116/200\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 1.1371 - accuracy: 1.0000 - val_loss: 3.0395 - val_accuracy: 0.4444\n",
            "Epoch 117/200\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 1.1508 - accuracy: 0.9808 - val_loss: 3.0431 - val_accuracy: 0.4444\n",
            "Epoch 118/200\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 1.1339 - accuracy: 1.0000 - val_loss: 3.0450 - val_accuracy: 0.4444\n",
            "Epoch 119/200\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 1.1681 - accuracy: 0.9808 - val_loss: 3.0046 - val_accuracy: 0.4444\n",
            "Epoch 120/200\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 1.1449 - accuracy: 1.0000 - val_loss: 2.9587 - val_accuracy: 0.5000\n",
            "Epoch 121/200\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 1.1518 - accuracy: 0.9808 - val_loss: 2.8930 - val_accuracy: 0.6111\n",
            "Epoch 122/200\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 1.1483 - accuracy: 1.0000 - val_loss: 2.8170 - val_accuracy: 0.6111\n",
            "Epoch 123/200\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 1.1325 - accuracy: 1.0000 - val_loss: 2.7491 - val_accuracy: 0.6111\n",
            "Epoch 124/200\n",
            "2/2 [==============================] - 0s 84ms/step - loss: 1.1430 - accuracy: 1.0000 - val_loss: 2.6880 - val_accuracy: 0.6667\n",
            "Epoch 125/200\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 1.1354 - accuracy: 1.0000 - val_loss: 2.6364 - val_accuracy: 0.6667\n",
            "Epoch 126/200\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 1.1329 - accuracy: 1.0000 - val_loss: 2.5973 - val_accuracy: 0.6667\n",
            "Epoch 127/200\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 1.1435 - accuracy: 1.0000 - val_loss: 2.5791 - val_accuracy: 0.6667\n",
            "Epoch 128/200\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 1.1309 - accuracy: 1.0000 - val_loss: 2.5633 - val_accuracy: 0.6667\n",
            "Epoch 129/200\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 1.1304 - accuracy: 1.0000 - val_loss: 2.5498 - val_accuracy: 0.6667\n",
            "Epoch 130/200\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 1.2026 - accuracy: 0.9808 - val_loss: 2.5257 - val_accuracy: 0.6667\n",
            "Epoch 131/200\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 1.1302 - accuracy: 1.0000 - val_loss: 2.4946 - val_accuracy: 0.6667\n",
            "Epoch 132/200\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 1.1301 - accuracy: 1.0000 - val_loss: 2.4710 - val_accuracy: 0.6667\n",
            "Epoch 133/200\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 1.2722 - accuracy: 0.9808 - val_loss: 2.4473 - val_accuracy: 0.6111\n",
            "Epoch 134/200\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 1.1342 - accuracy: 1.0000 - val_loss: 2.4203 - val_accuracy: 0.6667\n",
            "Epoch 135/200\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 1.1299 - accuracy: 1.0000 - val_loss: 2.3956 - val_accuracy: 0.6667\n",
            "Epoch 136/200\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 1.1312 - accuracy: 1.0000 - val_loss: 2.3731 - val_accuracy: 0.6667\n",
            "Epoch 137/200\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 1.1282 - accuracy: 1.0000 - val_loss: 2.3530 - val_accuracy: 0.6667\n",
            "Epoch 138/200\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 1.1289 - accuracy: 1.0000 - val_loss: 2.3343 - val_accuracy: 0.6667\n",
            "Epoch 139/200\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 1.1312 - accuracy: 1.0000 - val_loss: 2.3161 - val_accuracy: 0.6667\n",
            "Epoch 140/200\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 1.1286 - accuracy: 1.0000 - val_loss: 2.2987 - val_accuracy: 0.6667\n",
            "Epoch 141/200\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 1.1432 - accuracy: 1.0000 - val_loss: 2.2771 - val_accuracy: 0.6667\n",
            "Epoch 142/200\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 1.1331 - accuracy: 1.0000 - val_loss: 2.2611 - val_accuracy: 0.6667\n",
            "Epoch 143/200\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 1.1561 - accuracy: 0.9808 - val_loss: 2.2611 - val_accuracy: 0.7222\n",
            "Epoch 144/200\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 1.1296 - accuracy: 1.0000 - val_loss: 2.2583 - val_accuracy: 0.7222\n",
            "Epoch 145/200\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 1.1269 - accuracy: 1.0000 - val_loss: 2.2548 - val_accuracy: 0.7222\n",
            "Epoch 146/200\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 1.1825 - accuracy: 0.9808 - val_loss: 2.2654 - val_accuracy: 0.7222\n",
            "Epoch 147/200\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 1.1255 - accuracy: 1.0000 - val_loss: 2.2807 - val_accuracy: 0.7222\n",
            "Epoch 148/200\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 1.1342 - accuracy: 1.0000 - val_loss: 2.2912 - val_accuracy: 0.7222\n",
            "Epoch 149/200\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 1.1272 - accuracy: 1.0000 - val_loss: 2.2968 - val_accuracy: 0.7222\n",
            "Epoch 150/200\n",
            "2/2 [==============================] - 0s 84ms/step - loss: 1.1372 - accuracy: 1.0000 - val_loss: 2.2991 - val_accuracy: 0.7222\n",
            "Epoch 151/200\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 1.1241 - accuracy: 1.0000 - val_loss: 2.3035 - val_accuracy: 0.6667\n",
            "Epoch 152/200\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 1.1350 - accuracy: 1.0000 - val_loss: 2.3162 - val_accuracy: 0.6667\n",
            "Epoch 153/200\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 1.1256 - accuracy: 1.0000 - val_loss: 2.3357 - val_accuracy: 0.6667\n",
            "Epoch 154/200\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 1.1292 - accuracy: 1.0000 - val_loss: 2.3473 - val_accuracy: 0.6667\n",
            "Epoch 155/200\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 1.1226 - accuracy: 1.0000 - val_loss: 2.3522 - val_accuracy: 0.6667\n",
            "Epoch 156/200\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 1.1232 - accuracy: 1.0000 - val_loss: 2.3552 - val_accuracy: 0.6667\n",
            "Epoch 157/200\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 1.1856 - accuracy: 0.9808 - val_loss: 2.3377 - val_accuracy: 0.6667\n",
            "Epoch 158/200\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 1.1233 - accuracy: 1.0000 - val_loss: 2.3082 - val_accuracy: 0.7222\n",
            "Epoch 159/200\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 1.1215 - accuracy: 1.0000 - val_loss: 2.2850 - val_accuracy: 0.7222\n",
            "Epoch 160/200\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 1.1808 - accuracy: 0.9615 - val_loss: 2.2830 - val_accuracy: 0.7222\n",
            "Epoch 161/200\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 1.1791 - accuracy: 0.9808 - val_loss: 2.2777 - val_accuracy: 0.6667\n",
            "Epoch 162/200\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 1.1317 - accuracy: 1.0000 - val_loss: 2.2539 - val_accuracy: 0.6667\n",
            "Epoch 163/200\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 1.1202 - accuracy: 1.0000 - val_loss: 2.2348 - val_accuracy: 0.6667\n",
            "Epoch 164/200\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 1.1505 - accuracy: 1.0000 - val_loss: 2.2080 - val_accuracy: 0.6667\n",
            "Epoch 165/200\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 1.1203 - accuracy: 1.0000 - val_loss: 2.1797 - val_accuracy: 0.6667\n",
            "Epoch 166/200\n",
            "2/2 [==============================] - 0s 84ms/step - loss: 1.1561 - accuracy: 0.9808 - val_loss: 2.1523 - val_accuracy: 0.6667\n",
            "Epoch 167/200\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 1.1322 - accuracy: 1.0000 - val_loss: 2.1307 - val_accuracy: 0.7778\n",
            "Epoch 168/200\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 1.2626 - accuracy: 0.9615 - val_loss: 2.1001 - val_accuracy: 0.7778\n",
            "Epoch 169/200\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 1.1285 - accuracy: 1.0000 - val_loss: 2.0763 - val_accuracy: 0.7778\n",
            "Epoch 170/200\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 1.1641 - accuracy: 0.9808 - val_loss: 2.0487 - val_accuracy: 0.7778\n",
            "Epoch 171/200\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 1.1489 - accuracy: 0.9808 - val_loss: 2.0301 - val_accuracy: 0.7778\n",
            "Epoch 172/200\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 1.1419 - accuracy: 1.0000 - val_loss: 2.0090 - val_accuracy: 0.7778\n",
            "Epoch 173/200\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 1.1240 - accuracy: 1.0000 - val_loss: 1.9820 - val_accuracy: 0.7222\n",
            "Epoch 174/200\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 1.1181 - accuracy: 1.0000 - val_loss: 1.9586 - val_accuracy: 0.7222\n",
            "Epoch 175/200\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 1.1174 - accuracy: 1.0000 - val_loss: 1.9406 - val_accuracy: 0.6667\n",
            "Epoch 176/200\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 1.1166 - accuracy: 1.0000 - val_loss: 1.9256 - val_accuracy: 0.6667\n",
            "Epoch 177/200\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 1.1192 - accuracy: 1.0000 - val_loss: 1.9144 - val_accuracy: 0.6667\n",
            "Epoch 178/200\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 1.1393 - accuracy: 0.9808 - val_loss: 1.9052 - val_accuracy: 0.6667\n",
            "Epoch 179/200\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 1.1157 - accuracy: 1.0000 - val_loss: 1.8995 - val_accuracy: 0.6667\n",
            "Epoch 180/200\n",
            "2/2 [==============================] - 0s 84ms/step - loss: 1.1164 - accuracy: 1.0000 - val_loss: 1.8938 - val_accuracy: 0.6667\n",
            "Epoch 181/200\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 1.1155 - accuracy: 1.0000 - val_loss: 1.8886 - val_accuracy: 0.6667\n",
            "Epoch 182/200\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 1.1213 - accuracy: 1.0000 - val_loss: 1.8874 - val_accuracy: 0.6667\n",
            "Epoch 183/200\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 1.1383 - accuracy: 0.9808 - val_loss: 1.8843 - val_accuracy: 0.6667\n",
            "Epoch 184/200\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 1.1142 - accuracy: 1.0000 - val_loss: 1.8773 - val_accuracy: 0.7222\n",
            "Epoch 185/200\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 1.1362 - accuracy: 0.9808 - val_loss: 1.8689 - val_accuracy: 0.7222\n",
            "Epoch 186/200\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 1.1136 - accuracy: 1.0000 - val_loss: 1.8596 - val_accuracy: 0.7222\n",
            "Epoch 187/200\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 1.1173 - accuracy: 1.0000 - val_loss: 1.8522 - val_accuracy: 0.7222\n",
            "Epoch 188/200\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 1.1141 - accuracy: 1.0000 - val_loss: 1.8473 - val_accuracy: 0.7222\n",
            "Epoch 189/200\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 1.1147 - accuracy: 1.0000 - val_loss: 1.8422 - val_accuracy: 0.7222\n",
            "Epoch 190/200\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 1.1130 - accuracy: 1.0000 - val_loss: 1.8373 - val_accuracy: 0.7778\n",
            "Epoch 191/200\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 1.1122 - accuracy: 1.0000 - val_loss: 1.8322 - val_accuracy: 0.7778\n",
            "Epoch 192/200\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 1.1525 - accuracy: 0.9808 - val_loss: 1.8381 - val_accuracy: 0.7778\n",
            "Epoch 193/200\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 1.1770 - accuracy: 0.9808 - val_loss: 1.8477 - val_accuracy: 0.7778\n",
            "Epoch 194/200\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 1.1109 - accuracy: 1.0000 - val_loss: 1.8596 - val_accuracy: 0.7222\n",
            "Epoch 195/200\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 1.1294 - accuracy: 0.9808 - val_loss: 1.8746 - val_accuracy: 0.7222\n",
            "Epoch 196/200\n",
            "2/2 [==============================] - 0s 91ms/step - loss: 1.1225 - accuracy: 1.0000 - val_loss: 1.8905 - val_accuracy: 0.6667\n",
            "Epoch 197/200\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 1.1110 - accuracy: 1.0000 - val_loss: 1.9042 - val_accuracy: 0.6667\n",
            "Epoch 198/200\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 1.1097 - accuracy: 1.0000 - val_loss: 1.9126 - val_accuracy: 0.6667\n",
            "Epoch 199/200\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 1.1264 - accuracy: 0.9808 - val_loss: 1.9109 - val_accuracy: 0.6667\n",
            "Epoch 200/200\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 1.1107 - accuracy: 1.0000 - val_loss: 1.9092 - val_accuracy: 0.6667\n",
            "> 66.667\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        blur       1.00      0.67      0.80         3\n",
            "      normal       0.40      0.67      0.50         3\n",
            "        dark       1.00      0.67      0.80         3\n",
            "       glare       0.75      1.00      0.86         3\n",
            "     damaged       0.50      0.67      0.57         3\n",
            "     covered       1.00      0.33      0.50         3\n",
            "\n",
            "    accuracy                           0.67        18\n",
            "   macro avg       0.78      0.67      0.67        18\n",
            "weighted avg       0.77      0.67      0.67        18\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNmHGOxOtIap",
        "outputId": "70fe1e62-3a3b-471c-b923-974700a64711",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "name = 'mobilenet'\n",
        "save_model(model, name)\n",
        "\n",
        "write_to_output(model, name, classes, testX, testY, test_paths, True)\n",
        "\n",
        "write_to_output(model, name, classes, trainX, trainY, train_paths, False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n",
            "Written to output CSV\n",
            "Written to output CSV\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}